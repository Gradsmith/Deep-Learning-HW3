{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgh8g/Ktu+KQf7a3nOIEJs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gradsmith/Deep-Learning-HW3/blob/main/DL2022_HW3_P2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "85pB_KvHoiwQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2eb35fe-aa26-46fe-f7d3-9f1c841fb4f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting image-classifiers\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from keras-applications<=1.0.8,>=1.0.7->image-classifiers) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from keras-applications<=1.0.8,>=1.0.7->image-classifiers) (3.1.0)\n",
            "Installing collected packages: keras-applications, image-classifiers\n",
            "Successfully installed image-classifiers-1.0.0 keras-applications-1.0.8\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "try:\n",
        "    from classification_models.tfkeras import Classifiers\n",
        "except:\n",
        "    !pip install image-classifiers\n",
        "    from classification_models.tfkeras import Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part A)"
      ],
      "metadata": {
        "id": "i5vcnjqBucL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load a pretrained resnet50 model on imagenet and detach the FC layer\n",
        "resnet50_pretrained = ResNet50(input_shape=(32,32,3), weights='imagenet', include_top=False)"
      ],
      "metadata": {
        "id": "pFrzx1xDk9rh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3354f42-f870-4c9c-92a8-c6134fba4fc4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze the resnet50 conv layers to avoid weight changes during the linear tuning\n",
        "for layer in resnet50_pretrained.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "_bi_OA4orQbR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add a FC layer and GA pooling and create the teacher model\n",
        "model_teacher = tf.keras.Sequential()\n",
        "model_teacher.add(resnet50_pretrained)\n",
        "model_teacher.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "model_teacher.add(tf.keras.layers.Dense(10))"
      ],
      "metadata": {
        "id": "Y_Tj06edpRb7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the optimizer, loss and metrics\n",
        "model_teacher.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "vJoiBmhPmn2A"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the cifar10 dataset and apply the resnet specific preprocessing\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "x_train = preprocess_input(x_train)\n",
        "x_test = preprocess_input(x_test)"
      ],
      "metadata": {
        "id": "ZUBYf0SfvixR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4680cafd-bc23-4b36-8aec-7a8246683228"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tuning the teacher model\n",
        "model_teacher.fit(x_train, y_train, batch_size=32, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-8ib-6wvrV-",
        "outputId": "b026dc5a-277f-4d84-eb3a-5a60d3c68e12"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 33s 14ms/step - loss: 1.5760 - sparse_categorical_accuracy: 0.5749\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 22s 14ms/step - loss: 1.2372 - sparse_categorical_accuracy: 0.6406\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 23s 15ms/step - loss: 1.1745 - sparse_categorical_accuracy: 0.6590\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 22s 14ms/step - loss: 1.1512 - sparse_categorical_accuracy: 0.6666\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 22s 14ms/step - loss: 1.1301 - sparse_categorical_accuracy: 0.6741\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 23s 15ms/step - loss: 1.1176 - sparse_categorical_accuracy: 0.6780\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 22s 14ms/step - loss: 1.1206 - sparse_categorical_accuracy: 0.6778\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 22s 14ms/step - loss: 1.1162 - sparse_categorical_accuracy: 0.6828\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 22s 14ms/step - loss: 1.1119 - sparse_categorical_accuracy: 0.6849\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 22s 14ms/step - loss: 1.0984 - sparse_categorical_accuracy: 0.6837\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff426039820>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the teacher\n",
        "loss_train, acc_train = model_teacher.evaluate(x_train, y_train, batch_size=32)\n",
        "loss_test, acc_test = model_teacher.evaluate(x_test, y_test, batch_size=32)"
      ],
      "metadata": {
        "id": "wCGNCBT9wvpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae9d6d59-1998-424d-f30f-6ffab5ae01aa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 23s 14ms/step - loss: 1.0113 - sparse_categorical_accuracy: 0.7104\n",
            "313/313 [==============================] - 5s 14ms/step - loss: 1.6215 - sparse_categorical_accuracy: 0.6242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Test Loss: {loss_test:.3f}')\n",
        "print(f'Train Loss: {loss_train:.3f}\\n')\n",
        "\n",
        "print(f'Test Accuracy: {acc_test*100:.3f} %')\n",
        "print(f'Train Accuracy: {acc_train*100:.3f} %')"
      ],
      "metadata": {
        "id": "FFMUoRFszVhn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e34bee3-a1e4-4a12-f588-5d31129b3694"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.621\n",
            "Train Loss: 1.011\n",
            "\n",
            "Test Accuracy: 62.420 %\n",
            "Train Accuracy: 71.044 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part B)"
      ],
      "metadata": {
        "id": "XHB8lzNzzyRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load a untrained resnet18 model and detach the FC layer\n",
        "ResNet18, _ = Classifiers.get('resnet18')\n",
        "resnet18 = ResNet18(input_shape=(32,32,3), weights=None, include_top=False)"
      ],
      "metadata": {
        "id": "7R-f6EJM-sR-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add a FC layer and GA pooling and create the student model\n",
        "model_student = tf.keras.Sequential()\n",
        "model_student.add(resnet18)\n",
        "model_student.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "model_student.add(tf.keras.layers.Dense(10))\n",
        "\n",
        "# clone the student model to train from scratch in part c\n",
        "model_student_scratch = tf.keras.models.clone_model(model_student)\n",
        "\n",
        "# clone another student model to use in part d\n",
        "model_student_new = tf.keras.models.clone_model(model_student)"
      ],
      "metadata": {
        "id": "yZCvnO0IKPYL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# distill teacher to student with a distiller class\n",
        "# code adapted from https://keras.io/examples/vision/knowledge_distillation/\n",
        "\n",
        "class Distiller(tf.keras.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super(Distiller, self).__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        alpha=0.1,\n",
        "        temperature=3,\n",
        "    ):\n",
        "        \"\"\" Configure the distiller.\n",
        "\n",
        "        Args:\n",
        "            optimizer: Keras optimizer for the student weights\n",
        "            metrics: Keras metrics for evaluation\n",
        "            student_loss_fn: Loss function of difference between student\n",
        "                predictions and ground-truth\n",
        "            distillation_loss_fn: Loss function of difference between soft\n",
        "                student predictions and soft teacher predictions\n",
        "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
        "            temperature: Temperature for softening probability distributions.\n",
        "                Larger temperature gives softer distributions.\n",
        "        \"\"\"\n",
        "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack data\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass of teacher\n",
        "        teacher_predictions = self.teacher(x, training=False)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass of student\n",
        "            student_predictions = self.student(x, training=True)\n",
        "\n",
        "            # Compute losses\n",
        "            student_loss = self.student_loss_fn(y, student_predictions)\n",
        "\n",
        "            # Compute scaled distillation loss from https://arxiv.org/abs/1503.02531\n",
        "            # The magnitudes of the gradients produced by the soft targets scale\n",
        "            # as 1/T^2, multiply them by T^2 when using both hard and soft targets.\n",
        "            distillation_loss = (\n",
        "                self.distillation_loss_fn(\n",
        "                    tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
        "                    tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
        "                )\n",
        "                * self.temperature**2\n",
        "            )\n",
        "\n",
        "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics configured in `compile()`.\n",
        "        self.compiled_metrics.update_state(y, student_predictions)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update(\n",
        "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
        "        )\n",
        "        return results\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Compute predictions\n",
        "        y_prediction = self.student(x, training=False)\n",
        "\n",
        "        # Calculate the loss\n",
        "        student_loss = self.student_loss_fn(y, y_prediction)\n",
        "\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(y, y_prediction)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"student_loss\": student_loss})\n",
        "        return results"
      ],
      "metadata": {
        "id": "-66oz7dSOLyX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize and compile distiller\n",
        "distiller = Distiller(student=model_student, teacher=model_teacher)\n",
        "distiller.compile(\n",
        "    optimizer='adam',\n",
        "    metrics=['sparse_categorical_accuracy'],\n",
        "    student_loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=tf.keras.losses.KLDivergence(),\n",
        "    alpha=0.7,\n",
        "    temperature=2,\n",
        ")"
      ],
      "metadata": {
        "id": "Gvw4x2IJC09r"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# distill teacher's knowledge to student\n",
        "distiller.fit(x_train, y_train, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEpn5ealKh9X",
        "outputId": "b02aaa52-0a45-47f1-87c6-3b02ac7f72f2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 58s 34ms/step - sparse_categorical_accuracy: 0.5074 - student_loss: 1.4030 - distillation_loss: 3.2038\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - sparse_categorical_accuracy: 0.6553 - student_loss: 1.0050 - distillation_loss: 2.4860\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 52s 34ms/step - sparse_categorical_accuracy: 0.7166 - student_loss: 0.8291 - distillation_loss: 2.2244\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 53s 34ms/step - sparse_categorical_accuracy: 0.7593 - student_loss: 0.7032 - distillation_loss: 2.0695\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 53s 34ms/step - sparse_categorical_accuracy: 0.7918 - student_loss: 0.6099 - distillation_loss: 1.9442\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 53s 34ms/step - sparse_categorical_accuracy: 0.8259 - student_loss: 0.5179 - distillation_loss: 1.8356\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 53s 34ms/step - sparse_categorical_accuracy: 0.8537 - student_loss: 0.4378 - distillation_loss: 1.7366\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 53s 34ms/step - sparse_categorical_accuracy: 0.8756 - student_loss: 0.3815 - distillation_loss: 1.6697\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 53s 34ms/step - sparse_categorical_accuracy: 0.9002 - student_loss: 0.3189 - distillation_loss: 1.5961\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 53s 34ms/step - sparse_categorical_accuracy: 0.9133 - student_loss: 0.2834 - distillation_loss: 1.5534\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff4ef58fc40>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the student\n",
        "acc_train, student_loss_train = distiller.evaluate(x_train, y_train)\n",
        "acc_test, student_loss_test = distiller.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "b2V_G0BfYMNE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fca5605-8067-46e0-846a-d33d23f94669"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 14s 9ms/step - sparse_categorical_accuracy: 0.9388 - student_loss: 0.2192\n",
            "313/313 [==============================] - 3s 8ms/step - sparse_categorical_accuracy: 0.7717 - student_loss: 0.7089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Student Test Loss: {student_loss_test:.3f}')\n",
        "print(f'Student Train Loss: {student_loss_train:.3f}\\n')\n",
        "\n",
        "print(f'Test Accuracy: {acc_test*100:.3f} %')\n",
        "print(f'Train Accuracy: {acc_train*100:.3f} %')"
      ],
      "metadata": {
        "id": "UpxPJddMLQdH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "548370c4-9b2a-409c-f8a1-a6a783a8db9a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student Test Loss: 0.428\n",
            "Student Train Loss: 0.543\n",
            "\n",
            "Test Accuracy: 77.170 %\n",
            "Train Accuracy: 93.878 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part C)"
      ],
      "metadata": {
        "id": "v_VB86ZgTDCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the optimizer, loss and metrics\n",
        "model_student_scratch.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "UMZJOw7ORwEZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training a student model from scratch\n",
        "model_student_scratch.fit(x_train, y_train, batch_size=32, epochs=10)"
      ],
      "metadata": {
        "id": "aWCunvhbTCn9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86e524de-9031-4544-8759-4b58d67353cd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 36s 22ms/step - loss: 1.4168 - sparse_categorical_accuracy: 0.4937\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 34s 22ms/step - loss: 1.0092 - sparse_categorical_accuracy: 0.6481\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 34s 22ms/step - loss: 0.8218 - sparse_categorical_accuracy: 0.7161\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 33s 21ms/step - loss: 0.6896 - sparse_categorical_accuracy: 0.7630\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 34s 21ms/step - loss: 0.5729 - sparse_categorical_accuracy: 0.8018\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 34s 22ms/step - loss: 0.4757 - sparse_categorical_accuracy: 0.8338\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3907 - sparse_categorical_accuracy: 0.8655\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 33s 21ms/step - loss: 0.3101 - sparse_categorical_accuracy: 0.8922\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 33s 21ms/step - loss: 0.2439 - sparse_categorical_accuracy: 0.9137\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 33s 21ms/step - loss: 0.2018 - sparse_categorical_accuracy: 0.9296\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff3bdf187c0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the student\n",
        "loss_train, acc_train = model_student_scratch.evaluate(x_train, y_train, batch_size=32)\n",
        "loss_test, acc_test = model_student_scratch.evaluate(x_test, y_test, batch_size=32)"
      ],
      "metadata": {
        "id": "Hc2kq_gMWM7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a731f1f3-49c3-4e49-a62f-874674d3bdb7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1067 - sparse_categorical_accuracy: 0.9640\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.8528 - sparse_categorical_accuracy: 0.7711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Test Loss: {loss_test:.3f}')\n",
        "print(f'Train Loss: {loss_train:.3f}\\n')\n",
        "\n",
        "print(f'Test Accuracy: {acc_test*100:.3f} %')\n",
        "print(f'Train Accuracy: {acc_train*100:.3f} %')"
      ],
      "metadata": {
        "id": "UEHlyPhtWM7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50f6dfcd-610e-4868-dc4e-c01a4295d089"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.853\n",
            "Train Loss: 0.107\n",
            "\n",
            "Test Accuracy: 77.110 %\n",
            "Train Accuracy: 96.396 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be seen, the test accuracy of the distilled model is slightly higher than the student model that we trained from scratch. This is due to the fact that the distilled model learned its knowledge (layer weights) from a teacher model. However, the train accuracy of the student model that we trained from scratch is roughly 3% higher, which suggests that this student model is overfitted to the training data given the huge difference between the test and train accuracy."
      ],
      "metadata": {
        "id": "891X-m5WLfMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part D)"
      ],
      "metadata": {
        "id": "KWMZOWvlWTDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unfreeze layers for fine tuning the whole model\n",
        "for layer in model_teacher.layers:\n",
        "    layer.trainable = True"
      ],
      "metadata": {
        "id": "2Wful42eWaad"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set a small learning rate for fine tuning\n",
        "model_teacher.compile(\n",
        "    optimizer=tf.keras.optimizers.SGD(learning_rate=1e-4, momentum=0.9),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "N9IE6kAIWxOs"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fine tune the teacher model\n",
        "model_teacher.fit(x_train, y_train, batch_size=32, epochs=5)"
      ],
      "metadata": {
        "id": "p9T5e8AoYWuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb6b137c-c8f2-46ad-a0ee-07192f32a341"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 68s 40ms/step - loss: 1.5885 - sparse_categorical_accuracy: 0.5219\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 61s 39ms/step - loss: 0.9770 - sparse_categorical_accuracy: 0.6664\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 61s 39ms/step - loss: 0.8149 - sparse_categorical_accuracy: 0.7206\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 61s 39ms/step - loss: 0.7645 - sparse_categorical_accuracy: 0.7407\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 61s 39ms/step - loss: 0.6878 - sparse_categorical_accuracy: 0.7659\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff4265d3520>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the teacher\n",
        "loss_train, acc_train = model_teacher.evaluate(x_train, y_train, batch_size=32)\n",
        "loss_test, acc_test = model_teacher.evaluate(x_test, y_test, batch_size=32)"
      ],
      "metadata": {
        "id": "edJCIEj5X5Ds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3daa2fd-bc31-41ea-aa39-564fb84eb833"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 23s 14ms/step - loss: 0.5361 - sparse_categorical_accuracy: 0.8355\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.8741 - sparse_categorical_accuracy: 0.7337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Test Loss: {loss_test:.3f}')\n",
        "print(f'Train Loss: {loss_train:.3f}\\n')\n",
        "\n",
        "print(f'Test Accuracy: {acc_test*100:.3f} %')\n",
        "print(f'Train Accuracy: {acc_train*100:.3f} %')"
      ],
      "metadata": {
        "id": "HK6SuQ_kX5Dt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0810d87-2af3-49b3-c700-8dd2ce70594e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.874\n",
            "Train Loss: 0.536\n",
            "\n",
            "Test Accuracy: 73.370 %\n",
            "Train Accuracy: 83.550 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected, the teacher model accuracy has increased. Now we distill the teacher's knowledge to a new student."
      ],
      "metadata": {
        "id": "k_L4gxDTX7QI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize and compile distiller\n",
        "distiller = Distiller(student=model_student_new, teacher=model_teacher)\n",
        "distiller.compile(\n",
        "    optimizer='adam',\n",
        "    metrics=['sparse_categorical_accuracy'],\n",
        "    student_loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=tf.keras.losses.KLDivergence(),\n",
        "    alpha=0.7,\n",
        "    temperature=2,\n",
        ")"
      ],
      "metadata": {
        "id": "yzJmiEOKZq3d"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# distill teacher's knowledge to student\n",
        "distiller.fit(x_train, y_train, epochs=10)"
      ],
      "metadata": {
        "id": "imqmPopOZq3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9c5bb46-6745-4509-9e7f-015e9381872a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 56s 33ms/step - sparse_categorical_accuracy: 0.5096 - student_loss: 1.3832 - distillation_loss: 2.1775\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - sparse_categorical_accuracy: 0.6663 - student_loss: 0.9603 - distillation_loss: 1.4267\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - sparse_categorical_accuracy: 0.7280 - student_loss: 0.7813 - distillation_loss: 1.2002\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - sparse_categorical_accuracy: 0.7743 - student_loss: 0.6550 - distillation_loss: 1.0639\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 53s 34ms/step - sparse_categorical_accuracy: 0.8119 - student_loss: 0.5541 - distillation_loss: 0.9809\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - sparse_categorical_accuracy: 0.8387 - student_loss: 0.4730 - distillation_loss: 0.9288\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - sparse_categorical_accuracy: 0.8715 - student_loss: 0.3937 - distillation_loss: 0.8735\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 53s 34ms/step - sparse_categorical_accuracy: 0.8925 - student_loss: 0.3336 - distillation_loss: 0.8468\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - sparse_categorical_accuracy: 0.9126 - student_loss: 0.2870 - distillation_loss: 0.8223\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - sparse_categorical_accuracy: 0.9292 - student_loss: 0.2433 - distillation_loss: 0.8025\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff374875550>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the student\n",
        "acc_train, student_loss_train = distiller.evaluate(x_train, y_train)\n",
        "acc_test, student_loss_test = distiller.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "Zyl_KwriZq3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff046791-b10a-4b2c-e32d-b2d167045250"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 14s 9ms/step - sparse_categorical_accuracy: 0.9515 - student_loss: 0.1911\n",
            "313/313 [==============================] - 3s 9ms/step - sparse_categorical_accuracy: 0.7870 - student_loss: 0.6404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Student Test Loss: {student_loss_test:.3f}')\n",
        "print(f'Student Train Loss: {student_loss_train:.3f}\\n')\n",
        "\n",
        "print(f'Test Accuracy: {acc_test*100:.3f} %')\n",
        "print(f'Train Accuracy: {acc_train*100:.3f} %')"
      ],
      "metadata": {
        "id": "j-X4PH4PZq3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ca24658-e241-4c40-8c0d-bde6014ac343"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student Test Loss: 0.438\n",
            "Student Train Loss: 0.744\n",
            "\n",
            "Test Accuracy: 78.700 %\n",
            "Train Accuracy: 95.146 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compared to the other student model, which gained its knowledge from the previous teacher, the test and train accuracy of the new student model has increased by about 2%. So it can be said that the better we train the teacher, the higher accuracy we can expect from the student after the distillation."
      ],
      "metadata": {
        "id": "pq7JLpmdaN7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save the models\n",
        "model_teacher.save('./Models_P2/model_teacher.h5')\n",
        "model_student_scratch.save('./Models_P2/model_student_scratch.h5')\n",
        "model_student.compile()\n",
        "model_student.save('./Models_P2/model_student.h5')\n",
        "model_student_new.compile()\n",
        "model_student_new.save('./Models_P2/model_student_new.h5')"
      ],
      "metadata": {
        "id": "aT5tm0kAwQ0E"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}